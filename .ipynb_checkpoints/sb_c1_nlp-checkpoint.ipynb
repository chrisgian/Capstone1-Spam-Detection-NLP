{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim as gs\n",
    "#import slugify as sg\n",
    "import nltk\n",
    "from re import sub # import sub to replace items in the followiong list comprehension\n",
    "from collections import defaultdict\n",
    "from sklearn.lda import LDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read Data, Split into \"Train\", \"Test\", \"Validate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('SMSSpamCollection',header= None, names = ('outcome', 'content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split Correct? True \n",
      "\n",
      " (\"N's in .. train:\", (3000, 2), 'test:', (1572, 2), 'validate:', (1000, 2))\n"
     ]
    }
   ],
   "source": [
    "n = 3000\n",
    "train = data.sample(n)\n",
    "test = data[~data.index.isin(train.index)]\n",
    "validate = test.sample(1000)\n",
    "test= test[~test.index.isin(validate.index)]\n",
    "split_correctly = 0 == sum(validate.index.isin(test.index)) + sum(test.index.isin(train.index)) + sum(validate.index.isin(train.index))\n",
    "set_n_sizes = 'N\\'s in .. train:', train.shape,'test:', test.shape,'validate:', validate.shape\n",
    "\n",
    "print(\n",
    "    'Data Split Correct?',\n",
    "    split_correctly,\n",
    "    '\\n'*2,\n",
    "    set_n_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prep_nlp(data_to_prep, stop_words_in):\n",
    "    # lower case it\n",
    "    clean = list(data_to_prep.str.lower())\n",
    "    # this will tokenize\n",
    "    clean = [[word for word in document.split()] for document in clean]\n",
    "    #stopwords_set1 = set(nltk.corpus.stopwords.words('english'))\n",
    "    words_to_remove = '|'.join(stopwords_set3)\n",
    "    symbol_remover = '[^A-Za-z0-9]+'\n",
    "    clean = [[sub(symbol_remover,'',word) for word in text] for text in clean]\n",
    "    clean = [[sub(words_to_remove,'',word) for word in text] for text in clean]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_set2 = set('for a of the and to in or'.split())\n",
    "stopwords_set3 = ''\n",
    "train_prepped = prep_nlp(data_to_prep = train.content, stop_words_in= stopwords_set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build unsupervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train_data, topic_n):\n",
    "    frequency = defaultdict(int)\n",
    "    for text in train_data:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "    # get freq > 1\n",
    "    word_freq_1plus = [[x for x in words if frequency[x] > 1] for words in train_data]\n",
    "    # Create dictionary\n",
    "    dictionary = gs.corpora.Dictionary(word_freq_1plus)\n",
    "    # Create Corpus\n",
    "    corpus = [dictionary.doc2bow(text) for text in train_data]\n",
    "    # corpus to tfidf\n",
    "    tfidf = gs.models.TfidfModel(corpus) \n",
    "    corp_tf = tfidf[corpus] \n",
    "    # Unsupervised Component. Reduce space into 300 topics. \n",
    "    topic_n = topic_n\n",
    "    lsi = gs.models.LsiModel(corp_tf, id2word=dictionary, num_topics = topic_n)\n",
    "    corp_topics = lsi[corp_tf] \n",
    "    return corp_topics, dictionary, tfidf, lsi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "built_model = build_model(train_data = train_prepped, topic_n = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Build supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(topic_vec):\n",
    "    x = pd.DataFrame([dict(row) for row in topic_vec[0]])\n",
    "    y = (train[\"outcome\"] == \"spam\").astype(int) \n",
    "    lda = LDA()\n",
    "    mask = np.array([~np.isnan(row).any() for row in x.values])\n",
    "    x_masked = x[mask]\n",
    "    y_masked = y[mask]\n",
    "    lda = lda.fit(x_masked,y_masked)\n",
    "    return lda,x_masked,y_masked, topic_vec[1],topic_vec[2], topic_vec[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98030050083472453"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = train_model(topic_vec  = built_model)\n",
    "sum(trained_model[0].predict(trained_model[1])==trained_model[2])/len(trained_model[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x2a47ebe8438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Test Model on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome                                            content\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "16     ham                         Oh k...i'm watching here:)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     U dun say so early hor... U c already then say...\n",
       "6     Even my brother is not like to speak with me. ...\n",
       "9     Had your mobile 11 months or more? U R entitle...\n",
       "14                  I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "16                           Oh k...i'm watching here:)\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_unseen(new_doc_in, stop_words_in, trained_model_in):\n",
    "    \n",
    "    dictionary_in = trained_model_in[3]\n",
    "    tfidf_in = trained_model_in[4]\n",
    "    lsi_in = trained_model_in[5]\n",
    "    lda_in = trained_model_in[0]\n",
    "    new_doc_in_content = pd.Series(new_doc_in.content)\n",
    "    new_doc_in_outcome = pd.Series(new_doc_in.outcome)\n",
    "    \n",
    "    query = prep_nlp(new_doc_in_content, stop_words_in= stop_words_in)\n",
    "    query_bow = [dictionary_in.doc2bow(corp) for corp in query]\n",
    "    query_tf = tfidf_in[query_bow] \n",
    "    \n",
    "    x_2 = pd.DataFrame([dict(tf) for tf in lsi_in[query_tf]])\n",
    "    mask = np.array([~np.isnan(row).any() for row in x_2.values])\n",
    "    x_2masked = x_2[mask]\n",
    "    y_2 = (new_doc_in_outcome == \"spam\").astype(int) \n",
    "    \n",
    "    y_2masked = np.array(y_2[mask])\n",
    "    x_2masked = lda_in.predict(x_2masked)\n",
    "    \n",
    "    return x_2masked,y_2masked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = [\"hey dude where are you\",\n",
    "           \"text 444 for a promotional treat\",\n",
    "           \"dont know what time it is\", \n",
    "           \"Our records indicate your Pension is under performing to see higher growth and up to 25% cash release reply PENSION for a free review. To opt out reply STOP\",\n",
    "          \"To start the process please reply YES. To opt out text STOP\",\n",
    "          \"i'm going to be 10 mins late\"]\n",
    "new_doc_results = ['ham','spam','ham','spam','spam','ham']\n",
    "external_data = pd.DataFrame({'content':new_doc, 'outcome':new_doc_results})\n",
    "\n",
    "predicted_test = predict_unseen(new_doc_in=test, stop_words_in = stopwords_set2, trained_model_in = trained_model)\n",
    "predicted_external = predict_unseen(new_doc_in=external_data, stop_words_in = stopwords_set2, trained_model_in = trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.Performance\n",
    "There are three performance metrics:\n",
    "1. \"Accuracy\" which tells us, what percent of predicted results equal the actual results\n",
    "2. \"Precision\": Of all all observations we predicted as spam, what is actually spam?\n",
    "3. \"Recall\": Of all observations actually spam, what percent did we predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(result_x, result_y):\n",
    "    \n",
    "    actual_positive = result_y == 1\n",
    "    actual_negative = result_y ==0\n",
    "    \n",
    "    true_positives = result_x[actual_positive] == 1\n",
    "    false_positives = result_x[actual_negative] == 1\n",
    "    true_negatives = result_x[actual_negative] == 0\n",
    "    false_negatives = result_x[actual_positive] == 0\n",
    "    \n",
    "    #A. Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "    #B. Precision = TP/(TP + FP)\n",
    "    #C. Recall = TP/(TP + FN)\n",
    "    accuracy = sum((result_x == result_y))/len(result_y)\n",
    "    precision = sum(true_positives) / (sum(true_positives) + sum(false_positives))\n",
    "    recall = sum(true_positives) / (sum(true_positives) + sum(false_negatives))\n",
    "    return [accuracy, precision, recall, len(result_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_on_train = performance(result_x=trained_model[0].predict(trained_model[1]),result_y=trained_model[2])\n",
    "performance_on_test = performance(result_x=predicted_test[0],result_y=predicted_test[1])\n",
    "performance_on_external = performance(result_x=predicted_external[0],result_y=predicted_external[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>external</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <th>% Spam / Ham Correct</th>\n",
       "      <td>0.977041</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <th>% Predicted Spam Actually Spam</th>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.977961</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <th>% Spam Detected</th>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.874384</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N Size</th>\n",
       "      <th></th>\n",
       "      <td>1568.000000</td>\n",
       "      <td>2995.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Test        Train  external\n",
       "Accuracy  % Spam / Ham Correct               0.977041     0.980301       1.0\n",
       "Precision % Predicted Spam Actually Spam     0.965116     0.977961       1.0\n",
       "Recall    % Spam Detected                    0.846939     0.874384       1.0\n",
       "N Size                                    1568.000000  2995.000000       6.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = pd.DataFrame({\n",
    "    'Train':performance_on_train,\n",
    "    'Test':performance_on_test,\n",
    "    'external':performance_on_external\n",
    "\n",
    "}).set_index(\n",
    "    [['Accuracy','Precision','Recall','N Size'],\n",
    "     ['% Spam / Ham Correct','% Predicted Spam Actually Spam','% Spam Detected','']])\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
