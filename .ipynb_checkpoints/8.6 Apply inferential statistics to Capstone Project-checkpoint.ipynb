{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "Goals: Look at the average number of stop words between ham and spam. I am doing this because it would be interesting to see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from re import sub # import sub to replace items in the followiong list comprehension\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "data = pd.read_table('SMSSpamCollection',header= None, names = ('outcome', 'content'))\n",
    "ham = data[data.outcome == 'ham']\n",
    "spam = data[data.outcome == 'spam']\n",
    "\n",
    "# Read Stop word and symbol set\n",
    "stopwords_set1 = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords_set1 = '\\\\s'+'\\\\s|\\\\s'.join(stopwords_set1)+'\\\\s'+'|^'.join(stopwords_set1)\n",
    "stopwords_set2 = set('for a of the and to in or'.split())\n",
    "stopwords_set2 = '\\\\s'+'\\\\s|\\\\s'.join(stopwords_set2)+'\\\\s'+'|^'.join(stopwords_set2)\n",
    "symbol_set1 =     symbol_remover = '[^A-Za-z0-9]+'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Test Stopword / Symbol occurances "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two sample, Two-Sided Test of means:\n",
    "This is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_test(find_me, data_spam, data_ham):\n",
    "    data_ham = data_ham.copy()\n",
    "    data_spam = data_spam.copy()\n",
    "    check_ham = data_ham.content.str.count(find_me)\n",
    "    check_spam = data_spam.content.str.count(find_me)\n",
    "    data_ham['check'] = check_ham\n",
    "    data_spam['check'] = check_spam\n",
    "    results = ttest_ind(data_ham['check'], data_spam['check'])[1]\n",
    "    return 'P-value:', results, 'ham:', check_ham.mean(),'spam:',check_spam.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Mean occurance of stopwords and symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis Tests:\n",
    "\n",
    "\n",
    "\n",
    "Test A.\n",
    "- H0: No Difference in mean occurance of NLTK English Stopwords in both Spam / Ham text messages \n",
    "- H1: There is a difference in mean occurance of stopwords\n",
    "\n",
    "Test B.\n",
    "- H0: No Difference in mean occurance of Custom Stopwords in both Spam / Ham text messages \n",
    "- H1: There is a difference in mean occurance of stopwords\n",
    "\n",
    "Test C.\n",
    "- H0: No Difference in mean occurance of Non Alphanumeric characters in both Spam / Ham text messages \n",
    "- H1: There is a difference in mean occurance of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('reject at the .001 level?',\n",
       " True,\n",
       " ('P-value:',\n",
       "  5.0858840590884166e-15,\n",
       "  'ham:',\n",
       "  3.290155440414508,\n",
       "  'spam:',\n",
       "  4.287817938420348))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A. Test stop word set 1\n",
    "test_a = word_test(find_me =stopwords_set1, data_ham= ham, data_spam=spam)\n",
    "'reject at the .001 level?', test_a[1] < .001, test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('reject at the .001 level?',\n",
       " True,\n",
       " ('P-value:',\n",
       "  5.7642036780624097e-43,\n",
       "  'ham:',\n",
       "  1.164559585492228,\n",
       "  'spam:',\n",
       "  2.0160642570281126))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B. Test stop word set 2\n",
    "test_b = word_test(find_me =stopwords_set2, data_ham= ham, data_spam=spam)\n",
    "'reject at the .001 level?', test_b[1] < .001, test_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('reject at the .001 level?',\n",
       " True,\n",
       " ('P-value:',\n",
       "  6.7010105678767329e-117,\n",
       "  'ham:',\n",
       "  14.41160621761658,\n",
       "  'spam:',\n",
       "  24.811244979919678))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C. Test stop word set 1\n",
    "test_c = word_test(find_me =symbol_set1, data_ham= ham, data_spam=spam)\n",
    "'reject at the .001 level?', test_c[1] < .001, test_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "- Test A: Reject Null that Means are same \n",
    "- Test B: Reject Null that Means are same\n",
    "- Test C: Reject Null that Means are same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Test Confidence Intervals\n",
    "\n",
    "Question: What kind of accuracy, precision, and recall do we expect to see in future samples given that our text messages are acquired and do not differ from the 5000 text messages utilized here? \n",
    "\n",
    "Approach: Using resampling, resample 100 text messages 10,000 times. Use these to build a sampling distribution for Accuracy, Precision, and Recall that we will see with 90% liklihood in future cases. \n",
    "\n",
    "Contents located in project document as it requires additional code to run.\n",
    "[Confidence Intervals in Accuracy, Precision, and Recall](https://github.com/chrisgian/Capstone1-Spam-Detection-NLP/blob/master/sb_c1_nlp.ipynb)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
